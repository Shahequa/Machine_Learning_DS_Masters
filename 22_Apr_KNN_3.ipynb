{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3955d789-fe61-4984-89fb-80a34263c03e",
   "metadata": {},
   "source": [
    "## KNN Assignment - 3\n",
    "**By Shahequa Modabbera**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5093b-25eb-483d-991b-372b5fb704ab",
   "metadata": {},
   "source": [
    "### Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a5c0f6-414a-498a-bf59-e096897836db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training  and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier object\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier\n",
    "knn = knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy= accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28630cc6-da5e-40a6-93d7-4adf10d6344b",
   "metadata": {},
   "source": [
    "In this code, we first load the `load_iris` dataset from sklearn.datasets. Then, we split the dataset into training and testing sets using `train_test_split` function.\n",
    "\n",
    "Next, we create a `KNeighborsClassifier` object, specifying the number of neighbors (k) as n_neighbors=3. We then train the classifier using the training data by calling the `fit` method.\n",
    "\n",
    "After training, we use the trained classifier to make predictions on the test set by calling the predict method. The predicted labels are stored in `y_pred`.\n",
    "\n",
    "Finally, we calculated the accuracy of the classifier by comparing the predicted labels with the true labels from the test set using the `accuracy_score` function. The accuracy is then printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef9308-3351-406b-9697-6722ea6e166d",
   "metadata": {},
   "source": [
    "### Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914693b-3584-4c92-9626-ceb05f6b3455",
   "metadata": {},
   "source": [
    "- load_boston dataset is not available in sklearn.datsets. So, we are using fetch_openml to load the boston dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30499d69-257b-4469-a312-06b0b8f80164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 21.65955337690632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = fetch_openml(data_id=531)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN regressor object\n",
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "# Train the regressor\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13e32a-aacf-4df6-a061-92836e9e9c27",
   "metadata": {},
   "source": [
    "### Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using cross-validation on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f6ff53-19b4-4ea4-8fe5-59a78e3d582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K value: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define the range of K values to try\n",
    "k_values = range(1,31)\n",
    "\n",
    "# Initialize an empty list to score the cross-validation scores\n",
    "cross_val_scores = []\n",
    "\n",
    "# Perform cross-validation for each K value\n",
    "for k in k_values:\n",
    "    # Create a KNN classifier with the current K value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Perform cross-validation with 5 folds\n",
    "    scores = cross_val_score(knn, X, y, cv=5)\n",
    "    \n",
    "    # Calculate the mean cross-validation score\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    # Append the mean score to the list of cross-validation scores\n",
    "    cross_val_scores.append(mean_score)\n",
    "\n",
    "# Find the index of the maximum scros-validation scores\n",
    "best_index = cross_val_scores.index(max(cross_val_scores))\n",
    "    \n",
    "# Find the optimal K value\n",
    "optimal_k = k_values[best_index]\n",
    "\n",
    "# print the optimal K valur\n",
    "print(\"Optimal K value:\", optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f96dd2-377d-4111-905a-835ad057403c",
   "metadata": {},
   "source": [
    "### Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b860e75-058d-48e6-b674-0778368cc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 20.60552941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = fetch_openml(data_id=531)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature scaling on the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN regressor with the desired number of neighbors\n",
    "k = 5\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Fit the regressor to the scaled training data\n",
    "knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "y_pred = knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE  to evaluate the model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e856c2-dd59-4868-bad8-e73b09803f84",
   "metadata": {},
   "source": [
    "### Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc3f1e5-61b3-4847-87b4-cf35334669c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier with the desired number of neighbors and weights\n",
    "k = 5\n",
    "weights = 'distance' # Weighted voting based on distance\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k, weights=weights)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model to evaluate its performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f8dfb-0090-4baa-a398-8a5287b80f42",
   "metadata": {},
   "source": [
    "### Q6. Implement a function to standardise the features before applying KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fc13c0-46f8-4956-8667-ab873cf113f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurace: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X_train, X_test):\n",
    "    # Initialize the StandardScaler object\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler to the training data and transform the training features\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test features using the fitted scaler from training data\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "# Implementing on the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Standardize the features\n",
    "X_train_std, X_test_std = standardize_features(X_train, X_test)\n",
    "\n",
    "# Initialize and fit the KNN classifier with standardized features\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_std, y_train)\n",
    "\n",
    "# Predict the class labels for the test data\n",
    "y_pred = knn_classifier.predict(X_test_std)\n",
    "\n",
    "# Calculate the accuracy of the model to evaluate its performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accurace:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546c2c9-1a21-4f20-8622-21946dc38dd9",
   "metadata": {},
   "source": [
    "In this code, the `standardize_features` function takes `X_train` and `X_test` as input, and it returns the standardized versions of the features. It uses the `StandardScaler` from `sklearn.preprocessing` to perform the standardization. The `fit_transform` method is used on the training data to fit the scaler and transform the training features, while the `transform` method is used on the test data to transform the test features using the fitted scaler from the training data.\n",
    "\n",
    "By standardizing the features, we ensure that all features have a mean of 0 and a standard deviation of 1, which helps in bringing the features to a similar scale and can improve the performance of the KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1f593-a593-49c1-ae65-af05e6b8b7bb",
   "metadata": {},
   "source": [
    "### Q7. Write a Python function to calculate the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f419de79-ddcd-4705-bc42-02dc0f9ea975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "    \n",
    "    Arguments:\n",
    "    point1 -- tuple or list containing the coordinates of the first point (e.g. [x1, y1])\n",
    "    point2 -- tuple or list containing the coordinates of the second point (e.g. [x2, y2])\n",
    "    \n",
    "    Returns:\n",
    "    The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        distance += (point1[i] - point2[i]) ** 2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "point1= [2,3]\n",
    "point2 = [5,7]\n",
    "\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ecb60-4a14-4f16-9417-f6ddeb1ce511",
   "metadata": {},
   "source": [
    "### Q8. Write a Python function to calculate the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbfad23-ffd2-4147-8e4d-9df2d6099c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points.\n",
    "    \n",
    "    Arguments:\n",
    "    point1 -- tuple or list containing the coordinates of the first point (e.g. [x1, y1])\n",
    "    point2 -- tuple or list containing the coordinates of the second point (e.g. [x2, y2])\n",
    "    \n",
    "    Returns:\n",
    "    The Manhattan distance between the two points.\n",
    "    \"\"\"\n",
    "    \n",
    "    distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        distance += abs(point1[i] - point2[i])\n",
    "    return distance\n",
    "\n",
    "point1= [2,3]\n",
    "point2 = [5,7]\n",
    "\n",
    "distance = manhattan_distance(point1, point2)\n",
    "print(distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
